model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K
Official model name open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K
Converting OpenCLIP weights
model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K
visual projection shape torch.Size([768, 512])
Setting center_writing_weights to False for OpenCLIP
Setting fold_ln to False for OpenCLIP
Loaded pretrained model open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K into HookedTransformer
Processing neuron 445 in layer 11
Processing neuron 627 in layer 11
Processing neuron 455 in layer 11
Processing neuron 440 in layer 11
Processing neuron 2 in layer 11
Processing neuron 505 in layer 11
Processing neuron 236 in layer 11
Processing neuron 166 in layer 11
Processing neuron 718 in layer 11
Processing neuron 649 in layer 11
Processing neuron 309 in layer 11
Processing neuron 524 in layer 11
Processing neuron 545 in layer 11
Processing neuron 281 in layer 11
Processing neuron 584 in layer 11
Processing neuron 190 in layer 11
Processing neuron 307 in layer 11
Processing neuron 161 in layer 11
Processing neuron 383 in layer 11
Processing neuron 217 in layer 11
Processing neuron 27 in layer 11
Processing neuron 581 in layer 11
Processing neuron 68 in layer 11
Processing neuron 695 in layer 11
Processing neuron 503 in layer 11
Processing neuron 596 in layer 11
Processing neuron 207 in layer 11
Processing neuron 258 in layer 11
